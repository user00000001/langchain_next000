# ğŸ¦œï¸ğŸ”— LangChain + Next.js Starter Template

## ä¹‹å‰åªæ˜¯åœ¨æŸäº›å²—ä½æè¿°é‡Œè§è¿‡langchainç›¸å…³æè¿°ï¼Œæœ€å…ˆä»¥ä¸ºæ˜¯è·ŸåŒºå—é“¾ç›¸å…³ï¼Œåæ¥åˆæ­¥äº†è§£æ˜¯è·ŸAIç›¸å…³ã€‚æœºå™¨å­¦ä¹ æ–¹å‘å¥½ç‚¹å„¿çš„èŒä½ï¼Œåœ¨é¢è¯•ä¸Šæˆ‘è§‰å¾—åº”è¯¥å¾ˆä¾§é‡ç†è®ºæ¨å¯¼ï¼Œä¾‹å¦‚æ•°å­¦å…¬å¼é‚£äº›ã€‚è™½ç„¶æˆ‘æ—©åœ¨17å¹´çš„æ—¶å€™ï¼Œåœ¨å¼„çˆ¬è™«éªŒè¯ç çš„é‚£æ—¶ä¹Ÿå…¥é—¨è¿‡tensorflowæ¡†æ¶(pytorché‚£æ—¶æ‰åˆšå‡ºæ¥)ï¼Œä¸€äº›æœºå™¨å­¦ä¹ ç†è®ºä¹¦ç±ä¹Ÿçœ‹è¿‡éƒ¨åˆ†ï¼Œå‘ç°éœ€è¦æ•°å­¦ä»¥åŠç»Ÿè®¡çš„åŸºç¡€å¾ˆå¥½ï¼Œæ¯”å¦‚å½“æ—¶å¡åœ¨svmé‡Œçš„å¯¹å¶å‡½æ•°é‚£é‡Œã€‚è™½ç„¶æˆ‘è‡ªè®¤å·¥ç¨‹å®è·µæ–¹é¢è¿˜å¯ä»¥ï¼Œä½†æ˜¯è¦åœ¨æ­¤æ–¹å‘ä¸Šå¾—åˆ°å¥½ç‚¹å„¿çš„èŒä½ï¼Œææ€•æœ‰äº›éš¾ï¼Œå½“æ—¶ä¹Ÿæœ‰ç¡•å£«åšå£«åœ¨ç›¸å…³å²—ä½ä¸Šï¼Œå‘è§‰ä»–ä»¬çš„äº§å‡ºä¹Ÿä¸æ€ä¹ˆå¥½ï¼Œç§‘ç­å‡ºç”Ÿçš„äººéƒ½ä¸æ€ä¹ˆå¹²å¾—å¥½ï¼Œæ›´ä½•å†µåŠè·¯å‡ºå®¶çš„å‘¢ï¼Œæ‰€ä»¥é‚£æ—¶ä»¥åå°±æ²¡å»ä¾§é‡äºæœºå™¨å­¦ä¹ æ–¹å‘ã€‚

## æœ€è¿‘ä¸€å¹´chatgptå¿½ç„¶å˜æˆäº†è¯é¢˜ï¼Œå…¬å¸é‡Œä¹Ÿæœ‰äººåœ¨å¼„(è–…apiç©ï¼Œè‡ªèº«ä¸šåŠ¡åœæ»ï¼Œä¸Šçªœä¸‹è·³ï¼Œå¶å…¬å¥½é¾™ï¼Œåæ„Ÿ)ã€‚æˆ‘çš„åˆæ­¥è®¤è¯†æ˜¯ä¸€ä¸ªæ›´æ–¹ä¾¿æ™ºèƒ½çš„æœç´¢å¼•æ“ï¼Œç›®å‰è¿˜æ²¡çœ‹åˆ°æœ‰ä»€ä¹ˆå¯ä»¥å½¢æˆé•¿æœŸç¨³å®š,èƒ½å•†ä¸šé—­ç¯çš„é¡¹ç›®(å³ä¾¿æœ‰ï¼Œä¹Ÿä¼šå¾ˆå¿«é¢ä¸´åŒè´¨åŒ–ç«äº‰)ï¼Œå•†ä¸šä¸Šä¹Ÿåº”è¯¥æ˜¯çŸ­æœŸé¡¹ç›®æŒ£å¿«é’±ï¼Œæ‰€ä»¥å°±å˜æˆäº†æœ‰å¥½ç‚¹å­ä¸”å¿«é€Ÿäº¤ä»˜é¡¹ç›®ï¼Œæ¯”çš„æ˜¯å·¥ç¨‹ä¸Šçš„é›†æˆèƒ½åŠ›ï¼Œä¾§é‡fullstackï¼Œå°±æ¯”è¾ƒè´´åˆæˆ‘å·²æœ‰çš„æŠ€æœ¯æ ˆã€‚

## çœ‹äº†ä¸€äº›langchainçš„æ–‡æ¡£ï¼Œéƒ½æ˜¯pythonçš„ï¼Œä¹Ÿæ˜¯å‡†å¤‡åç«¯ç”¨pythonçš„,ä½†ipythonæµ‹è¯•çš„æ—¶å€™chromaçš„sqlite3ç‰ˆæœ¬ä¸æ»¡è¶³,pysqlite3-binaryä¹Ÿæ²¡èµ·ä½œç”¨(åè¯å®chromaçš„è§£å†³æ–¹æ¡ˆå¯è¡Œ),åˆ†æäº†æŠ¥é”™çš„ä»£ç ,å®‰è£…google.colabä¹Ÿæ— æ•ˆ,é‡æ–°ç”¨æºç ç¼–è¯‘äº†ä¹Ÿä¸èƒ½è§£å†³ï¼Œ(å¼€å‘æ¡Œé¢æ˜¯deepin 20.9,å®ƒçš„æœ€æ–°sqlite3åº“æ¯”chromaè¦æ±‚çš„3.35.0ä½,ä¹Ÿä¸æƒ³å»å‡çº§åˆ°æµ‹è¯•ç‰ˆç³»ç»Ÿ),æƒ³æ¥è¿˜æ˜¯å‰åç«¯ç”¨ç»Ÿä¸€typescript,å¥½ç¼–å†™è°ƒè¯•äº›ï¼Œåç«¯å‡†å¤‡ç”¨nestjsæ¥å†™ï¼Œåé¢æƒ³æ¥ä¹Ÿæ²¡å¿…è¦ï¼Œæ•´ä¸ªç”¨nextjsæ¥å¼„å†™ï¼Œä¸€ä¸ªå·¥ç¨‹æ›´æ–¹ä¾¿ã€‚å»çœ‹äº†langchainjsçš„æ–‡æ¡£å’Œä¸€äº›èµ„æ–™ï¼Œå‘ç°langchain-aié‡Œæœ¬å°±æœ‰è¿™ä¸ªæ–¹æ¡ˆçš„æ¨¡æ¿ï¼Œè€ƒè™‘åˆ°è‡ªå·±å¯¹è¿™äº›åº“çš„ä½¿ç”¨ä¹Ÿä¸ä¸€å®šå¾ˆç†Ÿæ‚‰ï¼Œåˆ°æ—¶è€—æ—¶é—´å»è°ƒè¯•ä¿®æ”¹ä»£ç ï¼Œæ²¡æ—¶é—´å»ç†è§£å®ç°åŠŸèƒ½ï¼Œæ‰€ä»¥å°±ç›´æ¥åŸºäºæ¨¡æ¿åº“æ”¹ï¼Œå®Œæˆäº†å†ç»†çœ‹ä¸€éä»£ç å°±è¡Œã€‚

## æ¨¡æ¿ä»£ç è¿è¡Œäº†ä¸‹ï¼Œå‘å‡ºpromptè¯·æ±‚åï¼Œå‘ç°æŠ¥é”™`Module not found: Package path ./utils/chunk_array is not exported from package`ï¼Œ@langchain+openaiçš„ä»£ç åº“ä¸­issueé‡Œä¹Ÿæ²¡æ‰¾åˆ°ç›¸å…³è§£å†³æ–¹æ¡ˆï¼ŒæŠŠ@langchainå¾€å‰å¾€åæ”¹ç‰ˆæœ¬ä¹Ÿä¸è¡Œï¼Œåœ¨changelogsé‡Œçœ‹åˆ°æœ€è¿‘ä¸€å‘¨ç¡®å®æœ‰`chunk_array`ç›¸å…³çš„æ”¹åŠ¨ï¼Œåæ¥æ ¹æ®æŠ¥é”™è·¯å¾„åœ¨node_moduleé‡Œçš„ä»£ç ä¸Šæ’æŸ¥ï¼Œç¡®å®æ²¡æœ‰ç›¸åº”çš„ä»£ç å®ç°ï¼Œç»§ç»­æ’æŸ¥ç‰ˆæœ¬ä¿¡æ¯ï¼Œåº”è¯¥æ˜¯@langchain/coreåº“åœ¨package.jsonä¸­è¢«å›ºå®šäº†ï¼Œæ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬ï¼Œè®¿é—®æŠ¥é”™æ’é™¤ã€‚ç„¶åå°±æ˜¯ä»£ç†é—®é¢˜(åœ¨ipythoné‡Œåšæµ‹è¯•ä¹Ÿé‡åˆ°è¿™ç§æƒ…å†µ)ï¼Œä½†æ˜¯pnpmåŠ all_proxyç¯å¢ƒå˜é‡æ— æ³•ç”Ÿæ•ˆï¼ŒOPENAI_API_KEYçš„æ·»åŠ æ–¹å¼ä¹Ÿä¸è¡Œï¼Œåé¢ä½¿ç”¨proxychainså»å¤„ç†çš„ä»£ç†é—®é¢˜,åŸŸåè§£ææŠ¥é”™,æ’é™¤äº†proxychainsçš„dnsä»£ç†,ä½†æ­å»ºæœ¬åœ°chromaæ—¶,æŠ¥`Error: Chroma getOrCreateCollection error: Error: TypeError: fetch failed`,æ’æŸ¥ä¸ºproxychainsæœªä»£ç†æ—¶æœªæ’é™¤æœ¬åœ°å±€åŸŸç½‘ç½‘æ®µ,å¯¼è‡´127.0.0.1è¯·æ±‚åˆ°äº†ä»£ç†æœåŠ¡å™¨,è®¿é—®è¿œç«¯çš„å¯¹åº”ç«¯å£æŠ¥é”™.

## ä½™ä¸‹çš„æ˜¯æ ¹æ®é¡¹ç›®è¦æ±‚å’Œå·²æœ‰çš„æ¨¡æ¿ä»£ç ï¼Œè¯¥ç²¾ç®€çš„ç²¾ç®€,è¯¥åŠ çš„åŠ ï¼Œè¯¥ç†è§£çš„ç†è§£,è¯¥æ³¨é‡Šçš„æ³¨é‡Šã€‚

### å°†æ¨¡æ¿ä¸­ä½¿ç”¨çš„è¿œç¨‹superbaseæ”¹ä¸ºæœ¬åœ°çš„chroma,ä¿®å¤äº†æ¨¡æ¿çš„ragåŠŸèƒ½,é™¤äº†Agentsé¡¹éœ€è¦ç¬¬ä¸‰æ–¹SearchApi Loaderæˆ–SerpAPI Loaderæ²¡æœ‰æœ¬åœ°åŒ–æ›¿ä»£å¤–,å…¶ä»–é¡¹éƒ½å¯ç”¨;æœ¬æƒ³å°†Chaté¡¹çš„historyæ”¾åœ¨äº†chromaé‡Œ,å…ˆä¸ä½œç”¨æˆ·ç”„åˆ«,æ¯æ¬¡ç‚¹å¼€é¡µé¢éƒ½æœ‰å†å²,ä½†æµ‹è¯•äº†äº›ä»£ç å‘ç°ç”¨ä¸äº†,æ‰€ä»¥ç”¨äº†pouchdb-browser,ç›´æ¥ä¿å­˜åœ¨å®¢æˆ·ç«¯æµè§ˆå™¨ä¸­,ä»…é’ˆå¯¹Chaté¡¹æœ‰æ•ˆ,æœ‰å¯¹è¯æ—¶åˆ·æ–°å¯ä»¥çœ‹è§æ•ˆæœ

## æ€»ç»“å°±æ˜¯æœ‰åˆ†æè§£å†³çªç°é—®é¢˜çš„èƒ½åŠ›,è¿˜éœ€ç†Ÿæ‚‰ä½¿ç”¨ç›¸å…³åº“,é¡¹ç›®å¼€å‘é€Ÿåº¦å°±å¿«.(æœŸé—´ç»•äº†äº›è·¯,åç«¯ç”¨ä¸å¤ªç†Ÿæ‚‰çš„nodeæ›¿æ¢python,æœ¬å¯ä»¥å‚è€ƒpythonçš„èµ„æ–™ç›´æ¥pythonå†™ï¼Œç”¨nodeè¿˜å¾—é‡æ–°çœ‹ç›¸å…³åº“çš„nodeå®ç°éƒ¨åˆ†çš„apiæ–‡æ¡£)

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/langchain-ai/langchain-nextjs-template)
[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Flangchain-nextjs-template)

This template scaffolds a LangChain.js + Next.js starter app. It showcases how to use and combine LangChain modules for several
use cases. Specifically:

- [Simple chat](/app/api/chat/route.ts)
- [Returning structured output from an LLM call](/app/api/chat/structured_output/route.ts)
- [Answering complex, multi-step questions with agents](/app/api/chat/agents/route.ts)
- [Retrieval augmented generation (RAG) with a chain and a vector store](/app/api/chat/retrieval/route.ts)
- [Retrieval augmented generation (RAG) with an agent and a vector store](/app/api/chat/retrieval_agents/route.ts)

Most of them use Vercel's [AI SDK](https://github.com/vercel-labs/ai) to stream tokens to the client and display the incoming messages.

![Demo GIF](/public/images/agent-convo.gif)

You can check out a hosted version of this repo here: https://langchain-nextjs-template.vercel.app/

## ğŸš€ Getting Started

First, clone this repo and download it locally.

Next, you'll need to set up environment variables in your repo's `.env.local` file. Copy the `.env.example` file to `.env.local`.
To start with the basic examples, you'll just need to add your OpenAI API key.

Next, install the required packages using your preferred package manager (e.g. `yarn`).

Now you're ready to run the development server:

```bash
yarn dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result! Ask the bot something and you'll see a streamed response:

![A streaming conversation between the user and the AI](/public/images/chat-conversation.png)

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

Backend logic lives in `app/api/chat/route.ts`. From here, you can change the prompt and model, or add other modules and logic.

## ğŸ§± Structured Output

The second example shows how to have a model return output according to a specific schema using OpenAI Functions.
Click the `Structured Output` link in the navbar to try it out:

![A streaming conversation between the user and an AI agent](/public/images/structured-output-conversation.png)

The chain in this example uses a [popular library called Zod](https://zod.dev) to construct a schema, then formats it in the way OpenAI expects.
It then passes that schema as a function into OpenAI and passes a `function_call` parameter to force OpenAI to return arguments in the specified format.

For more details, [check out this documentation page](https://js.langchain.com/docs/modules/chains/popular/structured_output).

## ğŸ¦œ Agents

To try out the agent example, you'll need to give the agent access to the internet by populating the `SERPAPI_API_KEY` in `.env.local`.
Head over to [the SERP API website](https://serpapi.com/) and get an API key if you don't already have one.

You can then click the `Agent` example and try asking it more complex questions:

![A streaming conversation between the user and an AI agent](/public/images/agent-conversation.png)

This example uses the OpenAI Functions agent, but there are a few other options you can try as well.
See [this documentation page for more details](https://js.langchain.com/docs/modules/agents/agent_types/).

## ğŸ¶ Retrieval

The retrieval examples both use Supabase as a vector store. However, you can swap in
[another supported vector store](https://js.langchain.com/docs/modules/data_connection/vectorstores/integrations/) if preferred by changing
the code under `app/api/retrieval/ingest/route.ts`, `app/api/chat/retrieval/route.ts`, and `app/api/chat/retrieval_agents/route.ts`.

For Supabase, follow [these instructions](https://js.langchain.com/docs/modules/data_connection/vectorstores/integrations/supabase) to set up your
database, then get your database URL and private key and paste them into `.env.local`.

You can then switch to the `Retrieval` and `Retrieval Agent` examples. The default document text is pulled from the LangChain.js retrieval
use case docs, but you can change them to whatever text you'd like.

For a given text, you'll only need to press `Upload` once. Pressing it again will re-ingest the docs, resulting in duplicates.
You can clear your Supabase vector store by navigating to the console and running `DELETE FROM docuemnts;`.

After splitting, embedding, and uploading some text, you're ready to ask questions!

![A streaming conversation between the user and an AI retrieval chain](/public/images/retrieval-chain-conversation.png)

![A streaming conversation between the user and an AI retrieval agent](/public/images/retrieval-agent-conversation.png)

For more info on retrieval chains, [see this page](https://js.langchain.com/docs/use_cases/question_answering/).
The specific variant of the conversational retrieval chain used here is composed using LangChain Expression Language, which you can
[read more about here](https://js.langchain.com/docs/guides/expression_language/cookbook). This chain example will also return cited sources
via header in addition to the streaming response.

For more info on retrieval agents, [see this page](https://js.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents).

## ğŸ“š Learn More

The example chains in the `app/api/chat/route.ts` and `app/api/chat/retrieval/route.ts` files use
[LangChain Expression Language](https://js.langchain.com/docs/guides/expression_language/interface) to
compose different LangChain modules together. You can integrate other retrievers, agents, preconfigured chains, and more too, though keep in mind
`BytesOutputParser` is meant to be used directly with model output.

To learn more about what you can do with LangChain.js, check out the docs here:

- https://js.langchain.com/docs/

## â–² Deploy on Vercel

When ready, you can deploy your app on the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme).

Check out the [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.

## Thank You!

Thanks for reading! If you have any questions or comments, reach out to us on Twitter
[@LangChainAI](https://twitter.com/langchainai), or [click here to join our Discord server](https://discord.gg/langchain).
